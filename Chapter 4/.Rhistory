AUCvals=CalcAUC(modlist[[ii]], data_sub = data_sub)
ModelTable$AUC[ii]=AUCvals[1]
ModelTable$Pres[ii]=AUCvals[2]
ModelTable$Abs[ii]=AUCvals[3]
rm(mod1,mod2, mod3, mod4, Qicdf)
}
# Add dummy dates for plotting (to fix the X axis)
AggData$DummyDate=as.Date(AggData$med, origin=as.Date("2013-01-01"))
AggData$UnitLoc=paste(AggData$GroupId, AggData$ShoreDist, sep="_")
AggData$BBEst=AggData$BNDTotOffset*AggData$OccAll
fit$DummyDate=as.Date(fit$JulienDay, origin=as.Date("2013-01-01"))
dummyfit$DummyDate=as.Date(dummyfit$JulienDay, origin=as.Date("2013-01-01"))
# colorblind palette with black:
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
temp=dummyfit[!duplicated(dummyfit$GroupId),]
# Plot all the data
ggplot(data=dummyfit) +
theme_bw() +
facet_wrap(~GroupId) +
scale_colour_manual(values=cbbPalette) +
geom_line(aes(DummyDate, inv.logit(fit), colour=ShoreDist), size=1) +
annotate("text", x=as.Date("2013-08-15"), y=1, label= as.character(temp$Year)) +
geom_ribbon(aes(x=DummyDate, ymin=inv.logit(lwr), ymax=inv.logit(upr), color=ShoreDist),
alpha=.2,linetype= 'blank') +
geom_point(data=AggData, aes(x=DummyDate, y=(BBEst),
color=ShoreDist), size=.9) +
xlab("") +
ylab("")
View(ModelTable)
#############
# Setup     #
#############
# This code investigates the various models that look at the different occupancy distributions
# incorporated by the data
rm(list=ls())
library(boot) # for inv.logit
library(mgcv)
library(ggplot2)
library(lme4)
library(dplyr) # for distinct function
library(geepack)
library(splines)
library(RColorBrewer)
library(MuMIn) # for QIC
setwd("W:/KJP PHD/4-Bayesian Habitat Use/R Code")
OccTable= read.csv('W:/KJP PHD/4-Bayesian Habitat Use/R Code/OccupancyTable_ThreePdets.csv')
level_names=c( "Lat_05", "Lat_10", "Lat_15",
"Hel_05", "Hel_10", "Hel_15",
"Cro_05", "Cro_10", "Cro_15",
"SpB_05", "SpB_10", "SpB_15",
"Fra_05", "Fra_10", "Fra_15",
"Cru_05", "Cru_10", "Cru_15",
"Sto_05", "Sto_10", "Sto_15",
"Abr_05", "Abr_10", "Abr_15",
"StA_05", "StA_10", "StA_15",
"Stb_05", "Stb_10", "Stb_15")
OccTable$UnitLoc=factor(OccTable$UnitLoc, levels=level_names)
OccTable$UnitLoc=(droplevels(OccTable)$UnitLoc)
meta=read.csv('W:/KJP PHD/CPOD Processing/2013 to 2016 SM deployments.csv')
meta$UnitLoc=factor(meta$UnitLoc, levels=level_names)
meta_sub=subset(meta, select=c('UnitLoc', 'Slope'))
OccTable=merge(OccTable, meta_sub, all.x = TRUE)
rm(meta_sub)
OccTable$IsCroFactor=ifelse(OccTable$UnitLoc=='Cro_05', 'Cro05','Other')
################################################################################
# General Data Prep #
################################################################################
OccTable$GroupId=unlist(strsplit(as.character(OccTable$UnitLoc), split = "_"))[seq(1,(nrow(OccTable)*2)-1,2)]
level_names=c( "Lat", "Hel", "Cro",
"SpB", "Fra", "Cru",
"Sto", "Abr", "StA",
"Stb")
OccTable$GroupId=factor(OccTable$GroupId, levels=level_names)
OccTable$ShoreDist=unlist(strsplit(as.character(OccTable$UnitLoc), split = "_"))[seq(2,(nrow(OccTable)*2),2)]
OccTable$JD_scale=scale(OccTable$JulienDay)
OccTable$FBOcc[is.na(OccTable$FBOcc)]=0
OccTable$BBOcc[is.na(OccTable$BBOcc)]=0
OccTable$UNKOcc[is.na(OccTable$UNKOcc)]=0
# Species offset for Occupancy
# If two species same hour and same unit then uncertain
OccTable$SpeciesOffset=OccTable$BBOcc+OccTable$FBOcc+OccTable$UNKOcc
OccTable$SpeciesOffset[OccTable$SpeciesOffset>1]=0.5
OccTable$SpeciesOffset[OccTable$SpeciesOffset==1 & OccTable$BBOcc==1]=0.77
OccTable$SpeciesOffset[OccTable$SpeciesOffset==1 & OccTable$FBOcc==1]=0.06
OccTable$SpeciesOffset[OccTable$SpeciesOffset==1 & OccTable$UNKOcc==1]=0.5
OccTable$SpeciesOffset[OccTable$SpeciesOffset==0] = 1
OccTable$BNDTotOffset=(OccTable$BBOcc*.77+OccTable$FBOcc*.06+OccTable$UNKOcc*.5)/(OccTable$BBOcc+OccTable$FBOcc+OccTable$UNKOcc)
OccTable$BNDTotOffset[is.nan(OccTable$BNDTotOffset)]=1
#####################################################
# Daily Occupancy #
#####################################################
# Add total number of detections
mm.bbtot=as.data.frame(aggregate(BBOcc~UnitLoc+Date, FUN=sum, data = OccTable))
colnames(mm.bbtot)[3]='BBTot'
mm.fbtot=as.data.frame(aggregate(FBOcc~UnitLoc+Date, FUN=sum, data = OccTable))
colnames(mm.fbtot)[3]='FBTot'
mm.unktot=as.data.frame(aggregate(UNKOcc~UnitLoc+Date, FUN=sum, data = OccTable))
colnames(mm.unktot)[3]='UNKTot'
mm=distinct(OccTable, Date, UnitLoc, JulienDay, GroupId, ShoreDist, Slope, Year,
Month, IsCroFactor, Hr)
mm.bb=distinct(subset(OccTable, BBOcc>0), Date, BBOcc, UnitLoc)
mm.fb=distinct(subset(OccTable, FBOcc>0), Date, FBOcc, UnitLoc)
mm.unk=distinct(subset(OccTable, UNKOcc>0), Date, UNKOcc, UnitLoc)
OccTable_daily=merge(mm, mm.bb, by = c('Date', 'UnitLoc'), all.x = TRUE)
OccTable_daily=merge(OccTable_daily, mm.fb, by = c('Date', 'UnitLoc'), all.x = TRUE)
OccTable_daily=merge(OccTable_daily, mm.unk, by = c('Date', 'UnitLoc'), all.x = TRUE)
OccTable_daily=merge(OccTable_daily, mm.bbtot, by = c('Date', 'UnitLoc'), all.x = TRUE)
OccTable_daily=merge(OccTable_daily, mm.fbtot, by = c('Date', 'UnitLoc'), all.x = TRUE)
OccTable_daily=merge(OccTable_daily, mm.unktot, by = c('Date', 'UnitLoc'), all.x = TRUE)
OccTable_daily[is.na(OccTable_daily)] <- 0
OccTable_daily$SpeciesOffset=OccTable_daily$BBOcc+OccTable_daily$FBOcc+OccTable_daily$UNKOcc
OccTable_daily$OccAll=ifelse(OccTable_daily$SpeciesOffset>=1,1,0)
# Species offset for Daily Occupancy
# If two species same day and same unit then uncertain
OccTable_daily$SpeciesOffset[OccTable_daily$SpeciesOffset>1]=0.5
OccTable_daily$SpeciesOffset[OccTable_daily$SpeciesOffset==1 & OccTable_daily$BBOcc==1]=0.77
OccTable_daily$SpeciesOffset[OccTable_daily$SpeciesOffset==1 & OccTable_daily$FBOcc==1]=0.06
OccTable_daily$SpeciesOffset[OccTable_daily$SpeciesOffset==1 & OccTable_daily$UNKOcc==1]=0.5
OccTable_daily$SpeciesOffset[OccTable_daily$SpeciesOffset==0] = 1
# Total offset
OccTable_daily$BNDTotOffset=(OccTable_daily$BBTot*.77+OccTable_daily$FBTot*.06+OccTable_daily$UNKTot*.5)/
(OccTable_daily$BBTot+OccTable_daily$FBTot+OccTable_daily$UNKTot)
OccTable_daily$TotDet=(OccTable_daily$BBTot+OccTable_daily$FBTot+OccTable_daily$UNKTot)
OccTable_daily$BNDTotOffset[is.na(OccTable_daily$BNDTotOffset)]=1
rm(mm, mm.bb, mm.fb, mm.unk, mm.bbtot, mm.fbtot, mm.unktot)
# Add a dummy variable and remove all days with no detections
mm=aggregate(data=OccTable, OccAll~Date+Year+UnitLoc, FUN = sum)
colnames(mm)[4]='SumHrlyDet'
OccTable=merge(OccTable, mm, all.x=TRUE)
OccTable_DPD=subset(OccTable, SumHrlyDet>0 )
################################################################################
# Function to calculate AUC #
################################################################################
# This function calculates AUC for the model (to access model fit) taken from
# Pirotta E, Matthiopoulos J, MacKenzie M, Scott-Hayward L, Rendell L Modelling sperm whale habitat preference: a novel approach combining transect and follow data
CalcAUC<-function(mod, data_sub){
pr <- predict(mod,data_sub, type="response")                          # the final model is used to predict the data on the response scale (i.e. a value between 0 and 1)
pred <- prediction(pr,data_sub$OccAll)                                    # to specify the vector of predictions (pr) and the vector of labels (i.e. the observed values "Pres")
perf <- performance(pred, measure="tpr", x.measure="fpr")          # to assess model performance in the form of the true positive rate and the false positive rate
plot(perf, colorize=TRUE, print.cutoffs.at=c(0.1,0.2,0.3,0.4,0.5)) # to plot the ROC curve
# Choice of the best cut-off probability
y<-as.data.frame(perf@y.values)
x<-as.data.frame(perf@x.values)
fi <- atan(y/x) - pi/4                                             # to calculate the angle between the 45° line and the line joining the origin with the point (x;y) on the ROC curve
L <- sqrt(x^2+y^2)                                                 # to calculate the length of the line joining the origin to the point (x;y) on the ROC curve
d <- L*sin(fi)                                                     # to calculate the distance between the 45° line and the ROC curve
# write.table(d,"C:\\distances.txt")                                # to write a table with the computed distances
# The table should then be opened in Microsoft Excel to find the maximum distance with the command "Sort", and the relative position (i.e. the number of the corresponding record)
# MAX d= 0.1127967 --> position 39
alpha<-as.data.frame(perf@alpha.values)                            # the alpha values represent the corresponding cut-offs
Best_cutoff=alpha[which.max(unlist(d)),]                           # to identify the alpha value (i.e. the cut-off) that corresponds to the maximum distance between the 45° line and the curve
# Best cutoff:   0.3464173
# This value can now be used to build the confusion matrix:
DATA<-matrix(0,nrow(data_sub),3)                                             # to build a matrix with 3 columns and n rows, where n is the dimension of the data set (here 919 - the number of rows can be checked with dim(dat))
DATA<-as.data.frame(DATA)
names(DATA)<-c("plotID","Observed","Predicted")
DATA$plotID<-1:nrow(data_sub)                                                # the first column is filled with an ID value that is unique for each row
DATA$Observed<-data_sub$OccAll                                                # the second column reports the observed response (0s and 1s)
DATA$Predicted<-predict(mod,data_sub,type="response")              # the third column reports the predictions
cmx(DATA, threshold = Best_cutoff)                                           # the identified cut-off must be used here
# Area under the Curve
auc <- unlist(performance(pred, measure="auc")@y.values)
# Proportion of the presences correctly identified
pres=prop.table(cmx(DATA, threshold = Best_cutoff))[1,1]
# Proportion of the absences correctly idenified
abs=prop.table(cmx(DATA, threshold = Best_cutoff))[2,2]
return(c(auc, pres, abs))
}
mod=geeglm(OccAll ~bs(HourAfterPeakSolEle, knots = mean(HourAfterPeakSolEle))+HourAfterHigh+GroupId+ShoreDist+Year,
corstr = 'ar1',
family = binomial, # leave out constrains
id=GroupId:Date,
offset = BNDTotOffset,
data = OccTable_DPD[OccTable_DPD$UnitLoc!='Cro_05',])
# Since yar does't give us much lets compare the models
mod1=geeglm(OccAll ~bs(HourAfterPeakSolEle, knots = mean(HourAfterPeakSolEle))+HourAfterHigh+GroupId+ShoreDist,
corstr = 'ar1',
family = binomial, # leave out constrains
id=GroupId:Date,
offset = BNDTotOffset,
data = OccTable_DPD[OccTable_DPD$UnitLoc!='Cro_05',])
CalcAUC(mod, data_sub=OccTable_DPD)
CalcAUC(mod1, data_sub=OccTable_DPD)
#______________________________________
#
# PLOT CONFIDENCE INTERVAL OF AN LM MODEL USING
# A SPECIFIED VARIANCE-COVARIANCE MATRIX
#
# Note:
# - This calculates the confidence interval of the mean from a fitted linear regression
#   when the estimated SE of coefficients is adjusted after model fitting.
# - The confidence interval is for the fitted mean; not to be confused with
#   prediction tolerance / prediction interval for individual observations.
#
# Warnings:
# - assumes normally distributed residuals *
# - it was only tested on lm() models and a specific plm() model with linear, categorical, and poly(..., raw=TRUE) terms
# - it does NOT produce proper confidence intervals with poly(..., raw=FALSE) terms
#
# Please send suggestions / report issues to Mick Wu (mick.wu@ufz.de)
# Updated: 2016-12-21
# Function to generate confidence intervals of the mean
# using a specific variance-covariance matrix
predictvcv <- function(mod, vcv, newdata, level=0.95){
# mod: regression model from which to extract coefficient estimates
# vcv: specified variance-covariance matrix for coefficients.
#    dimensions must match the number of terms in the model
# newdata: optional dataframe to predict new observations.
#          * It must also contain the response variable but the value does not matter
# level: level of confidence interval (default=95%
#
# returns a data frame with 3 variables: fitted mean, lower CI, upper CI
# Coefficient estimates
if (missing(mod)) stop("The fitted regression model 'mod' is missing")
beta.hat <- coef(mod)
# Variance covariance matrix
if (missing(vcv)){
warning("The covariance matrix 'vcv' is missing. It will be taken from 'the model'mod'")
vcv <- mod$geese$vbeta
}
if (any(length(beta.hat) != dim(vcv))) stop("'vcv' must be a square matrix with dimensions matching the number of terms in the regression model")
# Model matrix
if (missing(newdata)){
Xp <- model.matrix(mod)
} else {
f <- formula(mod)
Xp <- model.matrix(f,data=newdata)
}
# Predicted mean
pred <- as.numeric(Xp %*% beta.hat)
# SE (SD of mean)
se <- sqrt(unname(rowSums((Xp %*% vcv) * Xp)))
# quantile using the t-distribution
quant <- abs(qt((1-level)/2, df=mod$df.residual))
# output
return(data.frame(fit=pred, lwr=pred-(quant*se), upr=pred+(quant*se)) )
}
# #____________
# #   EXAMPLE
#
# #
# # Simulate data
# #
# x1 <- rnorm(1000, mean=0, sd=150) # continuous predictor
# x2 <- rep(0:1,each=500) # categorical predictor
# y <- 0.01*(x1^2) + 0.00005*(x1^3) + 2000*x2 + rnorm(1000, mean=0, sd=500) # response variable with dependencies
# # data frame
# dat <- data.frame(y,x1,x2)
# # new data frame for plotting a smooth confidence interval
# res = 100 # resolution for plotting
# newdat <- data.frame(y=0, x1 = rep(seq(min(x1),max(x1), # y is needed but values do not matter
#                      length.out=res),2), x2 = rep(0:1,each=res))
# rm(y,x1,x2,res) # clean up
# # plot the data
# plot(y~x1, col=hsv(h=(x2+0.2)/2, alpha=0.2), data=dat)
#
# #
# # Fit a linear regression with polynomials
# #
# mod <- lm(y ~ poly(x1,degree=3,raw = TRUE) + x2, data=dat)
# summary(mod)
#
# #
# # Plot different confidence intervals for comparison
# #
#
# # Plot the data with confidence intervals of the mean
# # using the normal predict function and fitted vcv
# plot(y~x1, col=hsv(h=0.1+x2/2, alpha=0.3), data=dat)
# prednew <- predict(mod, newdata=newdat, interval="confidence")
# index <- newdat$x2==0
# polygon(c(rev(newdat$x1[index]),newdat$x1[index]), c(rev(prednew[index,"lwr"]),prednew[index,"upr"]),
#         border=hsv(h=0.1+newdat$x2[index]/2, v=0.9),
#         col=hsv(h=0.1+newdat$x2[index]/2, alpha=0.3))
# index <- newdat$x2==1
# polygon(c(rev(newdat$x1[index]),newdat$x1[index]), c(rev(prednew[index,"lwr"]),prednew[index,"upr"]),
#         border=hsv(h=0.1+newdat$x2[index]/2, v=0.9),
#         col=hsv(h=0.1+newdat$x2[index]/2, alpha=0.3))
#
# # Plot the data with confidence intervals of the mean
# # using the predictvcv function
# # model with unchanged vcv (should be the same as predict function)
# predvcvnew <- predictvcv(mod, newdata=newdat)
# plot(y~x1, col=hsv(h=0.1+x2/2, alpha=0.3), data=dat)
# index <- newdat$x2==0
# polygon(c(rev(newdat$x1[index]),newdat$x1[index]), c(rev(predvcvnew[index,"lwr"]),predvcvnew[index,"upr"]),
#         border=hsv(h=0.1+newdat$x2[index]/2, v=0.9),
#         col=hsv(h=0.1+newdat$x2[index]/2, alpha=0.3))
# index <- newdat$x2==1
# polygon(c(rev(newdat$x1[index]),newdat$x1[index]), c(rev(predvcvnew[index,"lwr"]),predvcvnew[index,"upr"]),
#         border=hsv(h=0.1+newdat$x2[index]/2, v=0.9),
#         col=hsv(h=0.1+newdat$x2[index]/2, alpha=0.3))
# # model with an altered vcv
# vcv <- vcov(mod)
# diag(vcv) <- diag(vcv)*2
# predvcvnew <- predictvcv(mod, newdata=newdat, vcv=vcv)
# plot(y~x1, col=hsv(h=0.1+x2/2, alpha=0.3), data=dat)
# index <- newdat$x2==0
# polygon(c(rev(newdat$x1[index]),newdat$x1[index]), c(rev(predvcvnew[index,"lwr"]),predvcvnew[index,"upr"]),
#         border=hsv(h=0.1+newdat$x2[index]/2, v=0.9),
#         col=hsv(h=0.1+newdat$x2[index]/2, alpha=0.3))
# index <- newdat$x2==1
# polygon(c(rev(newdat$x1[index]),newdat$x1[index]), c(rev(predvcvnew[index,"lwr"]),predvcvnew[index,"upr"]),
#         border=hsv(h=0.1+newdat$x2[index]/2, v=0.9),
#         col=hsv(h=0.1+newdat$x2[index]/2, alpha=0.3))
fit=cbind(OccTable_DPD,  predictvcv(mod = mod, newdata = OccTable_daily))
fit=cbind(OccTable_DPD,  predictvcv(mod = mod, newdata = OccTable_DPD))
# Plot all the data
ggplot(data=fit) +
theme_bw() +
facet_wrap(~GroupId)
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# Plot all the data
ggplot(data=fit) +
theme_bw() +
facet_wrap(~GroupId) +
scale_colour_manual(values=cbbPalette) +
geom_line(aes(Hr, inv.logit(fit), colour=ShoreDist), size=1)
BootstrapParameters<-mvrnorm(10000, coef(mod), summary(mod)$cov.unscaled)
colnames(BootstrapParameters)
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
BS_idx
test<- glm(formula(mod),family=binomial, data=data_sub)
test<- glm(formula(mod),family=binomial, data=OccTable_DPD)
x1<-model.matrix(test)[,BS_idx]%*%coef(mod)[BS_idx]
BootstrapCoefs<- BootstrapParameters[,c(1, BS_idx)]
BootstrapCoefs
HourForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
test<- glm(formula(mod),family=binomial, data=OccTable_DPD)
HourForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
BootstrapParameters<-mvrnorm(10000, coef(mod), summary(mod)$cov.unscaled)
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
test<- glm(formula(mod),family=binomial, data=OccTable_DPD)
x1<-model.matrix(test)[,BS_idx]%*%coef(mod)[BS_idx]
BootstrapCoefs<- BootstrapParameters[,c(1, BS_idx)]
Basis<- cbind(rep(1,10), bs(HourForPlotting))
RealFit<- Basis%*%coef(mod)[c(1, BS_idx)]
length(HourForPlotting)
nreps=length(HourForPlotting)*10
nreps
nreps=length(HourForPlotting)*100
nreps
BootstrapParameters<-mvrnorm(length(HourForPlotting), coef(mod), summary(mod)$cov.unscaled)
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
test<- glm(formula(mod),family=binomial, data=OccTable_DPD)
x1<-model.matrix(test)[,BS_idx]%*%coef(mod)[BS_idx]
BootstrapCoefs<- BootstrapParameters[,c(1, BS_idx)]
Basis<- cbind(rep(1,10), bs(HourForPlotting))
Basis<- cbind(rep(1,nreps/100), bs(HourForPlotting))
RealFit<- Basis%*%coef(mod)[c(1, BS_idx)]
RealFit<- Basis%*%coef(mod)[c(1, BS_idx)]
str(Basis)
str(coef(mod)[c(1, BS_idx)])
coef(mod)
HourForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
BootstrapParameters<-mvrnorm(10000, coef(mod), summary(mod)$cov.unscaled)
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
HourForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
BootstrapParameters<-mvrnorm(10000, coef(mod), summary(mod)$cov.unscaled)
test<- glm(formula(mod),family=binomial, data=data_sub)
HourForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
BootstrapParameters<-mvrnorm(10000, coef(mod), summary(mod)$cov.unscaled)
test<- glm(formula(mod),family=binomial, data=data_sub)
HourForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
BootstrapParameters<-mvrnorm(10000, coef(mod), summary(mod)$cov.unscaled)
test<- glm(formula(mod),family=binomial, data=OccTable_DPD)
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
x1<-model.matrix(test)[,BS_idx]%*%coef(mod)[BS_idx]
BootstrapCoefs<- BootstrapParameters[,c(1, BS_idx)]
Basis<- cbind(rep(1,10), bs(HourForPlotting))
Basis<- cbind(rep(1,24), bs(HourForPlotting))
dim(Basis)
BS_idx
dim(coef(mod)[c(1, BS_idx)])
coef(mod)[c(1, BS_idx)]
RealFit<- Basis%*%coef(mod)[c(1, BS_idx)]
coef(mod)
library(MRSea)
(runPartialPlots())
(runPartialPlots)
c(1, grep('bs', colnames(model.matrix(mod))))
coefpos <- c(1, grep('bs', colnames(model.matrix(mod))))
xvals <- OccTable_DPD[, which(names(OccTable_DPD) == "HourAfterPeakSolEle")]
xvals
eval(parse(text = paste(varlist.in[i], "<- newX",  sep = "")))
eval(parse(text = paste("HourAfterPeakSolEle", "<- newX",  sep = "")))
newX <- seq(min(xvals), max(xvals), length = 500)
eval(parse(text = paste("HourAfterPeakSolEle", "<- newX",  sep = "")))
response <- rep(1, 500)
newBasis <- eval(parse(text = labels(terms(mod))[grep("HourAfterPeakSolEle",
labels(terms(model)))]))
newBasis <- eval(parse(text = labels(terms(mod))[grep("HourAfterPeakSolEle",
labels(terms(mod)))]))
newBasis
partialfit <- cbind(rep(1, 500), newBasis) %*% coef(mod)[coefpos]
partialfit <- cbind(rep(1, 500), newBasis) %*% coef(mod)[coefpos]
rcoefs <- NULL
try(rcoefs <- rmvnorm(1000, coef(model), summary(model)$cov.scaled),  silent = T)
if (is.null(rcoefs) || length(which(is.na(rcoefs) == T)) > 0) {
rcoefs <- rmvnorm(1000, coef(model), as.matrix(nearPD(summary(model)$cov.scaled)$mat))
}
partialfit <- cbind(rep(1, 500), newBasis) %*% coef(mod)[coefpos]
rcoefs <- NULL
try(rcoefs <- rmvnorm(1000, coef(mod), summary(mod)$cov.scaled),  silent = T)
if (is.null(rcoefs) || length(which(is.na(rcoefs) == T)) > 0) {
rcoefs <- rmvnorm(1000, coef(mod), as.matrix(nearPD(summary(mod)$cov.scaled)$mat))
}
rpreds <- cbind(rep(1, 500), newBasis) %*% t(rcoefs[, coefpos])
quant.func <- function(x) { quantile(x, probs = c(0.025, 0.975))}
cis <- t(apply(rpreds, 1, quant.func))
partialfit <- mod$family$linkinv(partialfit)
cis <- mod$family$linkinv(cis)
plot(xvals, par.res,
ylim = range(c(cis, par.res)), cex.lab = 1.3,
cex.axis = 1.3, col = "grey", cex = 0.5)
par.res <- residuals(mod, type = "partial")
par.res <- par.res[, c(grep(varlist.in[i], colnames(par.res)))]
par.res <- residuals(mod, type = "partial")
par.res
cis <- t(apply(rpreds, 1, quant.func))
cis
rpreds <- as.data.frame(rcoefs[, c(coefpos)])
str(rpreds)
coefpos
plot(newX, partialfit, type = "l")
response <- rep(1, 500)str(partialfit)
str(partialfit)
head(partialfit)
partialfit <- cbind(rep(1, 500), newBasis) %*% coef(mod)[coefpos]
rcoefs <- NULL
try(rcoefs <- rmvnorm(1000, coef(mod), summary(mod)$cov.scaled),  silent = T)
if (is.null(rcoefs) || length(which(is.na(rcoefs) == T)) > 0) {
rcoefs <- rmvnorm(1000, coef(mod), as.matrix(nearPD(summary(mod)$cov.scaled)$mat))
}
rpreds <- cbind(rep(1, 500), newBasis) %*% t(rcoefs[, coefpos])
quant.func <- function(x) {quantile(x, probs = c(0.025, 0.975))}
cis <- t(apply(rpreds, 1, quant.func))
partialfit <- mod$family$linkinv(partialfit)
cis <- mod$family$linkinv(cis)
plot(newX, partialfit, type = "l")
runPartialPlots(model = mod, data = OccTable_DPD, varlist.in = c('HourAfterPeakSolEle'))
str(mod)
formula(mod)
str(newBasis)
RealFit<- newBasis%*%coef(mod)[c(1, BS_idx)]
coef(mod)[c(1, BS_idx)]
# Get the smoothed index terms
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
x1<-model.matrix(test)[,BS_idx]%*%coef(mod)[BS_idx]
BootstrapCoefs<- BootstrapParameters[,c(1, BS_idx)]
Basis<- cbind(rep(1,10), bs(JdateForPlotting))
RealFit<- Basis%*%coef(mod)[c(1, BS_idx)]
str(Basis)
dims(Basis)
dim(Basis)
str(coef(mod)[c(1, BS_idx)])
coef(mod)
colnames(BootstrapParameters)
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
BS_idx
x1<-model.matrix(test)[,BS_idx]%*%coef(mod)[BS_idx]
BootstrapCoefs<- BootstrapParameters[,c(1, BS_idx)]
Basis<- cbind(rep(1,10), bs(JdateForPlotting))
HrForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
OccTable_DPD$HourAfterPeakSolEle
HrForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
HrForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
min(OccTable_DPD$HourAfterPeakSolEle)
max(OccTable_DPD$HourAfterPeakSolEle
seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
HrForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
HrForPlotting
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
BS_idx
x1<-model.matrix(test)[,BS_idx]%*%coef(mod)[BS_idx]
BootstrapCoefs<- BootstrapParameters[,c(1, BS_idx)]
Basis<- cbind(rep(1,10), bs(HrForPlotting))
Basis<- cbind(rep(1,100), bs(HrForPlotting))
HrForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
# Trim hour Date to be divisible by 10
if (length(HrForPlotting) %% 10>0){
HrForPlotting=HrForPlotting[-runif(length(HrForPlotting) %% 10, min=1, max=length(HrForPlotting))]
}
HrForPlotting
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
x1<-model.matrix(test)[,BS_idx]%*%coef(mod)[BS_idx]
BootstrapCoefs<- BootstrapParameters[,c(1, BS_idx)]
Basis<- cbind(rep(1,100), bs(HrForPlotting))
HrForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
length(HrForPlotting) %% 10>0
runif(length(HrForPlotting) %% 10, min=1, max=length(HrForPlotting)
)
HrForPlotting[-runif(length(HrForPlotting) %% 10, min=1, max=length(HrForPlotting))]
HrForPlotting=HrForPlotting[-runif(length(HrForPlotting) %% 10, min=1, max=length(HrForPlotting))]
length(HrForPlotting) %% 10
HrForPlotting<- seq(min(OccTable_DPD$HourAfterPeakSolEle), max(OccTable_DPD$HourAfterPeakSolEle))
# Trim hour Date to be divisible by 10
if (length(HrForPlotting) %% 10>0){
HrForPlotting=HrForPlotting[-runif(length(HrForPlotting) %% 10, min=1, max=length(HrForPlotting))]
}
length(HrForPlotting) %% 10>0
BS_idx=which(grepl("bs", colnames(BootstrapParameters)))
x1<-model.matrix(test)[,BS_idx]%*%coef(mod)[BS_idx]
BootstrapCoefs<- BootstrapParameters[,c(1, BS_idx)]
Basis<- cbind(rep(1,100), bs(HrForPlotting))
Basis<- cbind(rep(1,10), bs(HrForPlotting))
RealFit<- Basis%*%coef(mod)[c(1, BS_idx)]
BS_idx
c(1, BS_idx)
dim(Basis)
